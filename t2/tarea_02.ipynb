{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tarea_02",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56UFfKt75Yrl"
      },
      "source": [
        "# Surface Crack Binary Classification Dataset\n",
        "\n",
        "La detección de grietas juega un rol importante en la inspección y monitoreo de estructuras civiles. Si estas no son detectadas a tiempo, su propagación puede llegar a reducir paulatinamente la resistencia de la estructura y en el peor de los casos, provocar su colapso u otro tipo de daño irreversible. En general, la inspección manual para la detección de grietas suele ser un proceso tedioso y, en ocasiones, no resulta del todo efectivo al requerir del juicio subjetivo de un experto.\n",
        "\n",
        "Para integrar su conocimientos de Deep Learning a esta problemática, en esta tarea desarrollará modelos CNN para la detección binaria de grietas en imágenes de distinta calidad y resolución.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/cherrerab/deeplearningfallas/master/tarea_02/bin/banner.png\" height=\"180\">\n",
        "\n",
        "Cada uno de los datasets que utilizará en esta tarea contiene 2400 imágenes de superficies de hormigón con y sin grietas, junto con sus respectivas etiquetas para la clasificación. Los datasets han sido previamente separados en conjuntos de entrenamiento y testing, para una correcta evaluación de los modelos, en una proporción 80-20. De esta manera, para cada dataset tendrá 1920 imágenes para llevar a cabo el entrenamiento y 480 para testing.\n",
        "\n",
        "Dos aspectos o consideraciones importantes a la hora de desarrollar modelos de clasificación mediante redes convolucionales son la resolución y la calidad de las imágenes a utilizar. ¿Es necesario contar con imágenes de un gran resolución para obtener buenos resultados? ¿Qué tanto influye la presencia de ruido en el desempeño de un modelo CNN?\n",
        "\n",
        "Con el fin de determinar el efecto de estos factores, en esta tarea cuenta con los siguientes datasets en escala de grises.\n",
        "\n",
        "- `clean_cracks_96px.npz`: dataset original con imágenes de 96x96px.\n",
        "- `clean_cracks_28px.npz`: dataset original con las imágenes escaladas a 28x28px.\n",
        "- `noisy_cracks_96px.npz`: dataset con imágenes con ruido uniforme agregado de 96x96px.\n",
        "- `noisy_cracks_28px.npz`: dataset con imágenes con ruido uniforme agregado de 28x28px.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/cherrerab/deeplearningfallas/master/tarea_02/bin/banner_2.png\" height=\"180\">\n",
        "\n",
        "Como se mencionó anteriormente, cada uno de estos archivos cuenta con los conjuntos `X_train`, `Y_train`, `X_test` e `Y_test`, previamente definidos. En este caso, las imágenes se encuentran aplanadas en los datasets, de modo que los conjuntos `X_train` y `X_test` son de la forma `(n_samples, width*height)`. Por otro lado, vale señalar que las etiquetas `Y_train` e `Y_test` no se encuentran con `one-hot-encoding` y son de la forma `(n_samples, )`. Recuerde utilizar `np.reshape` y `keras.to_categorical` para reestructurar los arreglos a una forma compatible con las estructuras y capas de `keras`.\n",
        "\n",
        "Para facilitar la carga de los archivos a un entorno de Google Colab, los archivos han sido cargados a un Google Drive. Copie el siguiente bloque de código en su Notebook para ejecutar la rutina de descarga. Los archivos serán cargados en el directorio `\\content\\datasets`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8wt2bwTuylu"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# inicializar GoogleDrive con credenciales de autorización\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# crear carpeta para descargar los archivos .npz\n",
        "!mkdir /content/datasets\n",
        "\n",
        "# Google Drive IDs para descargar los archivos .npz\n",
        "files_id = [('clean_cracks_28px.npz', '1_ch0hhoNdXjnAW21OKiXgwwl8UqmzdP_'),\n",
        "            ('clean_cracks_96px.npz', '1d3pfc8GMVg6InF_-h0jCiG6d0uEYfuAp'),\n",
        "            ('noisy_cracks_28px.npz', '1YdiNowffR9ihXoQdqR56eTNzhi1ZaVCn'),\n",
        "            ('noisy_cracks_96px.npz', '1W2Civt30hWM3j1Lo4QiEHVDh15IE7ma-')]\n",
        "\n",
        "# comenzar descarga\n",
        "print('descargando datasets: ', end='')\n",
        "\n",
        "for filename, id in files_id:\n",
        "  save_path = os.path.join('/content/datasets', filename)\n",
        "\n",
        "  # descargar y guardar en /content/datasets\n",
        "  downloaded = drive.CreateFile({'id': id}) \n",
        "  downloaded.GetContentFile(save_path)\n",
        "\n",
        "# indicar descarga terminada\n",
        "print('done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbQVzV04dQPd"
      },
      "source": [
        "## Formato de Entrega\n",
        "\n",
        "Los entregables de esta tarea son los siguientes.\n",
        "- Jupyter Notebook (.ipynb): Todo el procesamiento de la tarea debe estar contenido en un único Notebook. Considere este archivo como un informe de metodología donde se reporten todos los pasos y bloques de código utilizados para resolver el problema. **Sea ordenado**; utilice comentarios en su código y bloques de texto para mejorar la legibilidad del Notebook.\n",
        "\n",
        "- Reporte Resultados (.pdf): Este archivo debe contener los resultados obtenidos en su tarea, junto con un análisis correspondiente. Considere este documento como la sección de Resultados y Análisis de la tarea. En este sentido, debe mantener un formato de informe estándar.\n",
        "\n",
        "## Recomendaciones\n",
        "\n",
        "- Active el acelerador de GPU dentro del entorno de Colab. El entrenamiento de modelos convolucionales suele requerir bastante más tiempo que el de modelos MLP o Fully Connected. En este sentido, procure también comenzar su tarea con anticipación pues no existirán extensiones de plazo para la entrega."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgrcYnbbdXYj"
      },
      "source": [
        "## 1. Classification Models\n",
        "\n",
        "Para cada una de los 4 datasets anteriormente descritos, implemente y optimice lo que más pueda un modelo convolucional de clasificación binaria mediante `keras`. Es decir, ajuste los hiperparámetros de cada modelo tal de maximizar el `accuracy` de clasificación en un conjunto de validación `(X_val, Y_val)`. Luego, para cada uno de estos cuatro modelos CNN reporte:\n",
        "\n",
        "- Media del accuracy en el conjunto de testing `(X_test, Y_test)` para 2 iteraciones.\n",
        "- Arquitectura o esquema del modelo.\n",
        "- Matriz de confusión.\n",
        "- Gráfico de la función de pérdida durante el entrenamiento.\n",
        "\n",
        "Comente sobre las diferencias de desempeño al utilizar los distintos datasets de imágenes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWjCQ5-rhZxM"
      },
      "source": [
        "## 2. Transfer Learning\n",
        "Similar al VGG-16, el ResNet es un modelo convolucional desarrollado por el equipo de Microsoft como arquitectura de visión computacional. Propuesto en el paper Deep Residual Learning for Image Recognition (2015), ResNet ganó el concurso ILSRVC 2015 superando el desempeño humano sobre el ImageNet dataset.\n",
        "\n",
        "https://keras.io/api/applications/resnet/#resnet50-function\n",
        "\n",
        "Mediante transfer learning, utilice la sección convolucional de ResNet50 para construir un modelo de clasificación de grietas. En particular, los pesos de la sección ResNet deben permanecer congelados durante el entrenamiento de este nuevo modelo.\n",
        "\n",
        "Entrene este modelo sobre los datasets `clean_cracks_96px` y `noisy_cracks_96px`. Para cada uno reporte:\n",
        "- Media del accuracy en el conjunto de testing `(X_test, Y_test)` para 2 iteraciones.\n",
        "- Matriz de confusión.\n",
        "- Gráfico de la función de pérdida durante el entrenamiento.\n",
        "\n",
        "Comente sobre las diferencias de desempeño respecto a los resultados de la Parte 1.\n"
      ]
    }
  ]
}