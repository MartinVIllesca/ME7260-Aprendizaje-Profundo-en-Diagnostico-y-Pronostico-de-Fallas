{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tarea_04.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuzYqIfkQJrH"
      },
      "source": [
        "# Stripping Column Anomaly Detection Autoencoder\n",
        "\n",
        "El Stripping consiste en un proceso físico de separación, en donde uno o más componentes son removidos de un flujo, líquido o gaseoso, mediante la inyección de otro fluido, usualmente a contraflujo.\n",
        "\n",
        "En esta tarea trabajarán sobre el caso de estudio de una columna de Stripping de una planta de extracción de gas natural, la cual está diseñada para remover, mediante la inyección de Amina, el exceso de CO2 en el gas natural. Lo particular de este sistema es que, cuando los sensores detectan un incremento en la concentración de CO2 por sobre el umbral nominal, se activa una alarma para indicar que la instalación presenta un funcionamiento anómalo.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/cherrerab/deeplearningfallas/master/tarea_04/bin/anomalies_plot.png\" height=\"400\">\n",
        "\n",
        "Así, el propósito de esta tarea es desarrollar un detector de anomalías en el funcionamiento de la columna de Stripping, mediante autoencoders. Similar al caso estudiado con los datos de CMAPSS, en el dataset `stripper_dataset.npz` cuentan con el registro temporal de `10 sensores`, organizados en ventanas temporales de `18 timesteps`, i.e el dataset es de la forma `(n_samples, n_timesteps, n_features)`. La tasa de muestreo del dataset es de `20min` por lo que cada ventana comprende un periodo de `6hrs` de registro.\n",
        "\n",
        "Adicionalmente, los conjuntos han sido previamente normalizados y separados en conjuntos de entrenamiento, validación, y testing `(X_train, X_val, X_test)`. Cada uno de estos conjuntos, por supuesto, cuentan con sus etiquetas `(Y_train, Y_val, Y_test)` las cuales contienen el estado de alarma de la columna de Stripping `2hrs` después de su ventana correspondiente, donde `1` indica estado de alarma, mientras que `0` indica un funcionamiento nominal en la planta.\n",
        "\n",
        "El dataset `stripper_dataset.npz` se encontrará disponible en el material docente del curso.\n",
        "\n",
        "## Formato de Entrega\n",
        "\n",
        "Los entregables de esta tarea son los siguientes.\n",
        "- Jupyter Notebook (.ipynb): Todo el procesamiento de la tarea debe estar contenido en un único Notebook. Considere este archivo como un informe de metodología donde se reporten todos los pasos y bloques de código utilizados para resolver el problema. **Sea ordenado**; utilice comentarios en su código y bloques de texto para mejorar la legibilidad del Notebook.\n",
        "\n",
        "- Reporte Resultados (.pdf): Este archivo debe contener los resultados obtenidos en su tarea, junto con un análisis correspondiente. Considere este documento como la sección de Resultados y Análisis de la tarea. En este sentido, debe mantener un formato de informe estándar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p6Gpj_f8nTU"
      },
      "source": [
        "## 1. Anomaly Detection\n",
        "\n",
        "Mediante `keras` implementen un `Vanilla Autoencoder` y entrénelo sobre las ventanas temporales `nominales` del conjunto de entrenamiento y validación `(X_train, X_val)`. El objetivo de esto es posteriormente utilizar el error de reconstrucción del `Autoencoder` como un discriminador de anomalías.\n",
        "\n",
        "Al evaluar su modelo sobre los datos de testing `(X_test)`, deberán definir un umbral de discrimación o `threshold` que, a partir del error de recontrucción de las ventanas temporales, segementará los datos anómalos de los nominales. De este modo, podrán realizar una clasificación binaria de los datos para generar las etiquetas `Y_pred`, que compararán con las etiquetas originales `Y_test`.\n",
        "\n",
        "El detector de anomalías debe priorizar la disminución de `falsos negativos`, es decir, cuando la planta presenta un estado anómalo en funcionamiento, pero el detector lo clasifica como nominal. En este sentido, no debe presentar más de `30 FN` en el conjunto de testing. Una vez hayan configurado su detector de anomalías, reporten:\n",
        "\n",
        "- Gráfico de función de pérdida durante el entrenamiento del `Autoencoder`. Una opción es utilizar como set de validación datos que presenten un estado de alarma, para así observar directamente la divergencia en el error de reconstrucción entre ambos conjuntos. Puede utilizar la función `plot_loss_function` presente en el GitHub del curso.\n",
        "- Gráfico que muestre la discriminación entre datos `nominales` y `anómalos` en función del umbral de su detector de anomalías. Pueden usar el gráfico de este enunciado como referencia.\n",
        "- Matriz de confusión que compare la clasificación de su detector de anomalías `(Y_pred)` con las etiquetas originales del conjuntos de testing `(Y_test)`. Puede utilizar la función `plot_confusion_matrix` presente en el GitHub del curso.\n",
        "- Gráfico ROC de la clasificación de su detector de anomalías sobre el conjunto de testing. Recuerden que mientras mayor sea la `AUC` (Area Under Curve) mejor será su discriminador de anomalías."
      ]
    }
  ]
}